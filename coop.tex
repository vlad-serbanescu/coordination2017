\section{Cooperative Scheduling Implementation Schemes}
\label{scheme}
-sequence diagram of what happens in an actor during synchronous and asynchronous method calls.

\subsection{Modeling Language Concepts in the JVM}
In this section we will investigate the evolution of the scheme used to implement cooperative scheduling in the Java Runtime environment from a very simple approach to using several libraries and features that the latest version of Java provides. Conceptually an actor has one thread of execution, which means it can run only one method at a time. Practically, however, allocating a real thread for each actor is highly expensive, as we can have a very large number of actors in the modeled application. Very roughly speaking, an executor service in Java provides a queue of tasks and an efficient way of running those tasks on a few threads. Due to the optimizations provided by Java implementations, an executor in principle is the best way to scale to many concurrent tasks. We use the terms executor and thread pool interchangeably, referring to the main interface \cite{execserv} that facilitate parallel programming in Java. 

\paragraph{An Actor has a lock and Every Asynchronous call is a Thread}
The trivial straightforward approach for implementing cooperative scheduling in Java is to model each actor as an object with a lock for which execution threads compete. Each asynchronous call would then generate a new thread with it own stack and context. The disadvantage here is that we will need a lock per actor that must be checked by every message handler upon start, and freed upon completion. Whenever a control switch statement occurs the thread would be suspended by the JVM's normal behavior. When the release condition is enabled a suspended thread would become available and in turn compete with the other available threads in order to execute on the actor. The main performance drawback of this approach is the large number of threads that are created, which restricts any application from having more method calls than the main memory can support live threads.

\paragraph{Every Actor is a Thread Pool}
To reduce the number of live threads in an application such that it can run independent of the number of asynchronous calls, we can use Java 8 new features and model each invocation as a task using lambda expressions and organize each actor as a Thread Pool. This gives the actor an implicit queue to which tasks are submitted. We obtain a small reduction in the number of threads corresponding to the number of tasks that have been submitted, but not started.  Once they are started the threads still have to compete for the actor's lock in order to execute, but the number of live threads can be restricted to the number of threads allowed by each Thread Pool, while the rest of the invocations remain in the pool thread pool queue as tasks. 

\paragraph{Every System has a Thread Pool}
In the previous two approaches we modeled the concept of an actor being restricted to one task at a time by introducing a lock on which threads compete. Up to this point we still haven't discussed the issue of suspension and release points. However with all invocations modeled as tasks that don't need a thread before they start, we can simply assign one thread of execution to each actor and submit just task to this thread. After all, there is no point in starting more than one task only to have it stuck on the actor's lock. Therefore we eliminate the lock and thread pool-per actor concepts and introduce one thread pool per system. The task corresponding to an actor is then responsible for taking messages one by one from the queue and running them. This removes the requirement to synchronize every message handler, but it comes at the cost of having to manage message queues manually.
Now the threads are only limited to the number of actors in the system...or are they? When cooperative scheduling occurs, the executing thread will be suspended and therefore still live in the system so the application's live threads will be equal to the number of "await" statements in the program. The application will then be limited by the maximum number of suspended threads that can exist in the main memory.  Furthermore we still require a lock to ensure than upon release this thread will only execute when the actor to which it belongs is idle.

\paragraph{Synchronous calls context}
To eliminate the problem of having live threads when cooperative scheduling occurs we can simply use lambda expressions to turn the continuation into a method call and pass its current state as parameters to the method. Essentially what we do is allocate memory for the continuation on the heap, while it is suspended instead of holding a stack for it which is much more limited.  We can maintain this call into a separate queue of tasks that are "awaiting" either  on a condition or on a future and insert it in the queue of the actor once it is released. The problem with this approach is that we cannot pass a state that represents a chain of synchronous calls within the actor that eventually encounters an await. In this particular scenario we would still have to save the call stack as a thread and encounter (although to a smaller extent) the same problem as in the previous paragraph. At most, we can give an increased priority to the suspended threads that save call stacks to execute on actors once they are released.

\paragraph{Fully Asynchronous Environment}
The only limitation Java has now is how avoid thread explosion when a chain of method calls is suspended within an actor, or in simpler terms how to save this call stack without using a thread? To do this we can try to alter the bytecode to resume execution at runtime from a particular point, but we want our approach to be independent of the runtime and be extensible to other programming languages. Therefore we try to approach the problem differently, if we can turn a continuation that does not originate from a stack of calls into a task, is it possible to extend this to synchronous calls as well? We know that this issue arises when methods that contain an "await" statement are called synchronously, but at compile time we can easily identify all of these methods form the ABS code. We can simply mark these methods at compile time and transform them into asynchronous calls followed by an "await" statement on the future generated from the call. Now we can use the same approach for translating these continuations into tasks using lambda expressions and thus eliminating any suspended threads in the system. There remains only one important issue of how these particular continuations are scheduled, but this approach together with the process of translating continuations into tasks with be detailed in Section\ref{comp}. 


\subsection{Optimizations for the JVM}
As we have seen and will also prove using a benchmark in Section \ref{bench} we improve performance by eliminating the number of expensive threads in Java that are required in order to implement the cooperative scheduling model. Using this data-oriented approach for saving contexts we limit any application to the system's main memory size, but added to that we also obtain some other optimizations related to Java's features.

\paragraph{Demand-driven Approach}
An important advantage of having a task assigned to each actor and a manually processed queue is that we can start and stop the task depending on the queue state. This is simply done by any other actor who sends an invocation to an empty queue and subsequently the task stops when there are no more tasks in the queue. An important observation to make here is the two scenarios when a release point may occur. As ABS semantics do not allow actors to modify each other's internal state, we know that a release point that will validate a boolean condition based on a change of an actor's state can only occur during another task that is already executing on that actor. This release point will always occur before the running task ends and therefore the queue can never be empty as the released message will be available in the queue and no special notification will be required to resume the task assigned to the actor. On the other hand, release points may also occur when actors fulfill a future and therefore we require the system to have a notification mechanism for actors with empty queues and newly enabled messages which we will detail in Section \ref{run}. This requires maintaining a global hash table, mapping every future to the set of actors that are awaiting on its completion.

\paragraph{Optimal Usage of System Threads}
The approach of using one thread pool per system gives the user direct control over the number of live threads the application creates. Using the Executor interface in Java allows the user to choose the type of thread pool that manages the actors and set the maximum number of threads that are available. For example the user can limit the number of threads the application has to the number of cores that the machine provides and avoid context switches made by the JVM. This is turn means that the implementation has to provide fair usage of the threads to the tasks that run the actors, an issue which we will also touch upon in Section \ref{run}.  

\paragraph{Eliminating Busy Waiting}
Cooperative scheduling through the "await" statements may suspend the current message run by the actor based on either a particular inner stare or future requiring completion on a different actor. We discussed how the task assigned to the actor can start or stop based on release points, but how exactly does an actor verify that a release point has completed ? Clearly having a task continuously iterate through all suspended messages (busy-waiting) is inefficient and while we can permanently mark a message that needs a future to complete as available, we cannot do that for a message which is released by particular valid state, as it the state can change by the time it is run. Instead we assign this verification to the task that fetches messages from the queue, and simply stop the task if no message is available. If the task does stop, it means that the actor is in a state in which it is unable to execute any of its messages and requires another actor to either send a new invocation that will change its state or the system to send a notification about a future that may release some of its messages and re-enable the task assigned to it.  


\paragraph{Using JVM Garbage Collection}
Using the approach explained so far in this section, the only extra references we need for the actors are the ones inside the global hash-table required for the notification mechanism. Once the future is completed and notifications are sent the key is deleted and the actor references become unreachable. Therefore we can leave the entire garbage collection process to the Java Runtime Environment as no other bookkeeping mechanisms are required.

